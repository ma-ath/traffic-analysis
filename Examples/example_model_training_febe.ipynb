{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cfd44d0",
   "metadata": {},
   "source": [
    "# Notebook modelo para o treinamento de modelos\n",
    "Este notebook jupyter é um modelo de exemplo para o treinamento de modelos. Ele está organizado para ser simples de entender e de fácil modificação, conforme a necessidade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0f01cf",
   "metadata": {},
   "source": [
    "### 1.Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c01bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "\n",
    "# Adiciona a pasta TrafficSoundAnalysis para o 'PATH', para que o python reconheça nosso pacote. Se isso falhar, não será possível fazer a importação dos pacotes\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "\n",
    "# Importa a classe DataHandler e ModelHandler da nossa biblioteca de tráfego\n",
    "from TrafficSoundAnalysis.DataHandler.DataHandler import *\n",
    "from TrafficSoundAnalysis.ModelHandler.ModelHandler import *\n",
    "\n",
    "# Importa o Tensorflow\n",
    "import tensorflow as tf\n",
    "# Força o Tensorflow a usar apenas uma GPU. Como a FEBE é compartilhada entre muitos usuários, isso é importante.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "\"\"\"\n",
    "# Isso aqui é para resolve um problema de 'Out Of Memory' na minha gpu (GTX 1650, 4gb)\n",
    "# Comentado aqui por que acho que não é necessário na FEBE.\n",
    "# https://stackoverflow.com/questions/59873568/unknownerror-failed-to-get-convolution-algorithm\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\"\"\"\n",
    "\n",
    "# Carrega o dicionário python com todos os folds\n",
    "from folds import *\n",
    "\n",
    "# Tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3bb87e",
   "metadata": {},
   "source": [
    "### 2.Importação do dataset extraído"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "671a1a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'path' para os dados. No caso, eles ainda estão na minha pasta principal.\n",
    "dataset_dir = '/home/mathlima/dataset'\n",
    "if not os.path.isdir(dataset_dir):\n",
    "    raise Exception(\"Pasta de dataset não encontrada\")\n",
    "\n",
    "# inicialização do objeto \"DataHandler\", que gerenciará os dados.\n",
    "dataHandler = DataHandler(dataset_directory = dataset_dir, image_format = [224, 224, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869f24a0",
   "metadata": {},
   "source": [
    "### 3.Geração do modelo a ser treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a28361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Cria um objeto do tipo ModelHandler() para geração do nosso modelo\n",
    "model = ModelHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b2e6ea",
   "metadata": {},
   "source": [
    "Inicialização de modelo por dicionário python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "695a7fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Modelo de dicionario python para definicao de uma rede\n",
    "network = dict()\n",
    "\n",
    "#   Model and training configuration\n",
    "network['model_name'] = 'training_example'\n",
    "network['input_format'] = [224, 224, 3]\n",
    "\n",
    "#   Convolutional layer\n",
    "network['cnn'] = 'vgg16' #or inceptionv3, or resnet50\n",
    "network['cnn_offline'] = True\n",
    "network['cnn_freeze_imagenet_weights'] = True\n",
    "\n",
    "#   Pooling layer\n",
    "network['pooling'] = 'gap'  #or 'none', or 'gmp'\n",
    "\n",
    "#   RNN Layer\n",
    "network['rnn'] = 'lstm' #   or 'lstm'\n",
    "network['rnn_timesteps'] = 32\n",
    "network['rnn_outputsize'] = 128\n",
    "network['rnn_dropout'] = 0.2\n",
    "network['rnn_isstateful'] = False\n",
    "\n",
    "#   Hidden FC layer\n",
    "network['hiddenfc'] = True\n",
    "network['hiddenfc_size'] = 128\n",
    "network['hiddenfc_activation'] = 'tanh'\n",
    "network['hiddenfc_regularizer'] = None\n",
    "network['hiddenfc_dropout'] = 0.2\n",
    "\n",
    "#   Dataset related things\n",
    "network['dataset_overlapwindows'] = True\n",
    "network['dataset_causalprediction'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1148895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 2, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 14,747,585\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.LoadModelFromDictionary(network)\n",
    "\n",
    "# O modelo keras gerado fica salvo no parametro '.model' do nosso objeto.\n",
    "# Vamos sumarizar o modelo gerado:\n",
    "\n",
    "# Summary\n",
    "model.model.summary()\n",
    "\n",
    "# Também podemos vizualizar o modelo com o método ShowModel()\n",
    "from IPython.display import Image\n",
    "\n",
    "model.ShowModel()\n",
    "Image(filename='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894054aa",
   "metadata": {},
   "source": [
    "### 4.Treinamento de redes neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75c9f283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[INFO]: \u001b[0mLoading non-extracted data from fold fold_0\n",
      "\u001b[92m[INFO]: \u001b[0mLoading data\n",
      "\u001b[92m[INFO]: \u001b[0mStarting building process for train dataset\n",
      "\u001b[92m[INFO]: \u001b[0mSize of ndarray of type np.uint8: 6.66796875 mb\n",
      "\u001b[92m[INFO]: \u001b[0mSize of ndarray of type np.ufloat32: 26.671875 mb\n",
      "\u001b[92m[INFO]: \u001b[0mStarting building process for test dataset\n",
      "\u001b[92m[INFO]: \u001b[0mFold built is complete\n",
      "\u001b[92m[INFO]: \u001b[0mDataset loaded sucessefully\n",
      "x_train.shape: (569, 64, 64, 3)\n",
      "y_train.shape: (569,)\n",
      "x_val.shape: (252, 64, 64, 3)\n",
      "y_val.shape: (252,)\n"
     ]
    }
   ],
   "source": [
    "#   Carregamos os dados necessários (Nesse caso, os dados do fold 0)\n",
    "[\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val\n",
    "] = dataHandler.LoadDataset(folds[0],\n",
    "                            CNN=\"vgg16\",\n",
    "                            CNN_offline=True,\n",
    "                            Pooling=\"gap\",\n",
    "                            LSTM=True,\n",
    "                            time_steps=32,\n",
    "                            overlap_windows=True,\n",
    "                            causal_prediction=False)\n",
    "\n",
    "print('x_train.shape:',x_train.shape)\n",
    "print('y_train.shape:',y_train.shape)\n",
    "print('x_val.shape:',x_val.shape)\n",
    "print('y_val.shape:',y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa86b3b",
   "metadata": {},
   "source": [
    "__Criação de 'Callbacks'__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Callback\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.0001,\n",
    "    decay_steps=10,\n",
    "    decay_rate=0.5,\n",
    "    staircase=False)\n",
    "\n",
    "learning_schedule = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Early stop Callback\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# ModelCheckpoint Callback\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "                    'model_checkpoint.hdf5',\n",
    "                    monitor='val_loss',\n",
    "                    verbose=2,\n",
    "                    save_best_only=True,\n",
    "                    save_weights_only=False,\n",
    "                    mode='auto')\n",
    "\n",
    "# Tensorboard\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='logs')\n",
    "\n",
    "# Geração dos callbacks para passar para o metodo .fit\n",
    "callback = [learning_schedule, model_checkpoint, earlystop, tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f0b013",
   "metadata": {},
   "source": [
    "__model.fit__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3e0b53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[INFO]: \u001b[0mModel was defined in the following dictionary:\n",
      "\tmodel_name = training_example\n",
      "\tinput_format = [64, 64, 3]\n",
      "\tcnn = vgg16\n",
      "\tcnn_offline = False\n",
      "\tcnn_freeze_imagenet_weights = True\n",
      "\tpooling = gap\n",
      "\trnn = none\n",
      "\trnn_timesteps = 10\n",
      "\trnn_outputsize = 64\n",
      "\trnn_dropout = 0.2\n",
      "\trnn_isstateful = False\n",
      "\thiddenfc = True\n",
      "\thiddenfc_size = 64\n",
      "\thiddenfc_activation = tanh\n",
      "\thiddenfc_regularizer = None\n",
      "\thiddenfc_dropout = 0\n",
      "\tdataset_overlapwindows = True\n",
      "\tdataset_causalprediction = False\n",
      "\u001b[92m[INFO]: \u001b[0mModel 'training_example' summary:\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 2, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 14,747,585\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "18/18 - 21s - loss: 116.9855 - val_loss: 50.1010\n",
      "Epoch 2/10\n",
      "18/18 - 1s - loss: 37.3359 - val_loss: 28.8190\n",
      "Epoch 3/10\n",
      "18/18 - 1s - loss: 24.2243 - val_loss: 18.6812\n",
      "Epoch 4/10\n",
      "18/18 - 1s - loss: 16.2622 - val_loss: 11.8744\n",
      "Epoch 5/10\n",
      "18/18 - 1s - loss: 10.9158 - val_loss: 7.3326\n",
      "Epoch 6/10\n",
      "18/18 - 1s - loss: 7.4826 - val_loss: 4.3693\n",
      "Epoch 7/10\n",
      "18/18 - 1s - loss: 5.3466 - val_loss: 2.5675\n",
      "Epoch 8/10\n",
      "18/18 - 1s - loss: 4.0714 - val_loss: 1.5448\n",
      "Epoch 9/10\n",
      "18/18 - 1s - loss: 3.3933 - val_loss: 0.9506\n",
      "Epoch 10/10\n",
      "18/18 - 1s - loss: 3.0273 - val_loss: 0.6243\n",
      "\u001b[92m[INFO]: \u001b[0mModel took 27.22 seconds to train on\n",
      "\u001b[92m[INFO]: \u001b[0mAverage time per epoch: 2.72 seconds\n",
      "\u001b[92m[INFO]: \u001b[0mSaving model information to disk\n"
     ]
    }
   ],
   "source": [
    "# Seguindo o padrão do Keras, primeiro compilamos o modelo:\n",
    "model.CompileModel()\n",
    "\n",
    "# E em seguida o treinamos com:\n",
    "fit_history = model.Train(x=x_train, y=y_train, validation_data=(x_val, y_val), epochs=10, callbacks=callback)\n",
    "\n",
    "# Por fim, salvamos o modelo no disco, da seguinte forma:\n",
    "model.SaveModel('.', fit_history=fit_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
